{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5af3fb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path1 = '/Users/steph/berkelab/DA_maze/DA/Modules/'\n",
    "path2 = '/Users/steph/berkelab/DA_maze/Behavior/Modules/'\n",
    "sys.path += [path1,path2]\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from multi_rat_da import *\n",
    "from tmat_ops import *\n",
    "from hexLevelAnalyses import get_sigRats_fromMeanList\n",
    "from photometryQuantifications import *\n",
    "#from scipy.stats import wilcoxonz\n",
    "from celluloid import Camera\n",
    "from pdf2image import convert_from_path\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c486ce5d",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "6d863118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    \"\"\" Given an array of numerical data, returns that data scaled between 0-1 \"\"\"\n",
    "    \n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "def scale_to_bounds(data, bounds):\n",
    "    \"\"\" Scales the values of the 'data' list to match the min and max of the 'bounds' list\n",
    "\n",
    "    Parameters:\n",
    "    data (list): The data list to be scaled.\n",
    "    bounds (list): The target bounds to which the data should be scaled.\n",
    "\n",
    "    Returns:\n",
    "    scaled_data (list): The scaled data list within the specified bounds.\n",
    "    \"\"\"\n",
    "\n",
    "    return (data-np.min(data)) / (np.max(data)-np.min(data)) * (np.max(bounds)-np.min(bounds)) + np.min(bounds)\n",
    "\n",
    "\n",
    "def get_bounds(df):\n",
    "    \"\"\" Given a dataframe with x and y fields, returns min(x), min(y), max(x), max(y) \"\"\"\n",
    "    \n",
    "    return np.nanmin(df.x), np.nanmin(df.y), np.nanmax(df.x), np.nanmax(df.y)\n",
    "\n",
    "\n",
    "def expand_second_list(first_list, second_list):\n",
    "    \"\"\" Expand the second list to match the size of the first list.\n",
    "\n",
    "    Args:\n",
    "    first_list (list): The list with counts or indices.\n",
    "    second_list (list): The list to be expanded.\n",
    "\n",
    "    Returns:\n",
    "    list: The expanded second list.\n",
    "\n",
    "    Example:\n",
    "    >>> first_list = [0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]\n",
    "    >>> second_list = [4, 5, 6, 7]\n",
    "    >>> expanded_second_list = expand_second_list(first_list, second_list)\n",
    "    >>> print(expanded_second_list)\n",
    "    [4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7]\n",
    "    \"\"\"\n",
    "    \n",
    "    expanded_second_list = [second_list[val] for val in first_list]\n",
    "    return expanded_second_list\n",
    "\n",
    "\n",
    "def moving_average(data, window_size=125):\n",
    "    \"\"\" Smooth a jumpy signal using a simple moving average filter.\n",
    "    \n",
    "    Parameters:\n",
    "    data (list): List of values to be smoothed.\n",
    "    window_size (int): Size of the moving average window. Default of 125 = 0.5s (at 250 Hz sample frequency)\n",
    "    \"\"\"\n",
    "    \n",
    "    if window_size <= 0 or window_size >= len(data):\n",
    "        raise ValueError(\"Invalid window size\")\n",
    "        \n",
    "    smoothed_data = []\n",
    "    for i in range(len(data)):\n",
    "        start = max(0, i - window_size + 1)\n",
    "        end = i + 1\n",
    "        window = data[start:end]\n",
    "        smoothed_value = sum(window) / len(window)\n",
    "        smoothed_data.append(smoothed_value)\n",
    "\n",
    "    return smoothed_data\n",
    "\n",
    "\n",
    "def convert_indices_to_time(indices, start_point=0, sample_frequency=250):\n",
    "    \"\"\" Given an array of indices and a sampling frequency (Hz), return corresponding time array (s)\n",
    "    \n",
    "    The returned time array will start from 0 seconds by default (better for plotting)\n",
    "    start_point = -1 means the start time of the returned array will not be adjusted\n",
    "    \"\"\"\n",
    "    \n",
    "    seconds_per_sample = 1/sample_frequency\n",
    "    if start_point == -1:\n",
    "        return indices*seconds_per_sample\n",
    "    else: # if not explicity set to -1, I choose to assume we want to start the time from 0 \n",
    "        return (indices-np.nanmin(indices))*seconds_per_sample\n",
    "    \n",
    "\n",
    "def find_dead_ends(tmat):\n",
    "    \"\"\" Given a transition matrix, returns a list of hexes that are dead ends \"\"\"\n",
    "    \n",
    "    dead_ends = np.unique(np.where(tmat==1)[0])\n",
    "    dead_ends = np.delete(dead_ends,np.isin(dead_ends,[1,2,3]))\n",
    "    \n",
    "    return dead_ends\n",
    "\n",
    "\n",
    "def path_to_dead_end(tmat, next_hex, path=[]):\n",
    "    \"\"\" Given a transition matrix and a dead end hex, recursively finds the path of hexes to that dead end \n",
    "    \n",
    "    Note: Third argument [] or name of empty list is required to ensure you get a new list \n",
    "    instead of modifying the same list from the last time this function was run\n",
    "    \"\"\"\n",
    "\n",
    "    path.append(next_hex)\n",
    "    next_hexes = np.where(tmat[:, next_hex]==0.5)[0]\n",
    "    \n",
    "    for hex in next_hexes:\n",
    "        if hex not in path and hex not in [1,2,3]:\n",
    "            path_to_dead_end(tmat, hex, path)\n",
    "            \n",
    "    return list(path)\n",
    "\n",
    "\n",
    "def get_all_dead_end_paths(tmat, min_length=1):\n",
    "    \"\"\" Given a transition matrix, get all paths to dead end hexes.\n",
    "    \n",
    "    Parameters: \n",
    "    tmat: the transition matrix\n",
    "    min_length (int): the minimum length of dead end path to include\n",
    "    \n",
    "    Returns: a list of lists, where each list starts with a dead end hex and \n",
    "    includes the path (in order) of hexes to that dead end.\n",
    "    \"\"\"\n",
    "\n",
    "    all_dead_end_paths = []\n",
    "    dead_ends = find_dead_ends(tmat)\n",
    "    \n",
    "    for hex in dead_ends:\n",
    "        path = path_to_dead_end(tmat, hex, [])\n",
    "        if len(path) >= min_length:\n",
    "            all_dead_end_paths.append(path)\n",
    "        \n",
    "    return list(all_dead_end_paths)\n",
    "\n",
    "\n",
    "def find_dead_end_path_for_hex(hexes, all_dead_end_paths):\n",
    "    \"\"\" Returns the dead end path (or list of paths) a hex (or hexes) is in, or [] if not in a dead end.\n",
    "    \n",
    "    Parameters: \n",
    "    hexes: A list of hexes, or a single hex\n",
    "    all_dead_end_paths: List of all dead end paths in the maze (in hexes)\n",
    "    \n",
    "    Returns: \n",
    "    A list of dead end paths the same length as hexes, where each entry is the dead end path that the hex is in\n",
    "    \n",
    "    (I use this to add a column of dead end paths to the dataframe so I can group by dead end)\n",
    "    \"\"\"\n",
    "    \n",
    "    # if we only want to check a single hex, that's fine\n",
    "    if isinstance(hexes, int):\n",
    "        return next((path for path in dead_end_paths if hexes in path), [])\n",
    "    \n",
    "    # otherwise, loop through all hexes and return a list of dead end paths for each hex\n",
    "    result = []\n",
    "    for hex in hexes:\n",
    "        dead_end_path = next((path for path in dead_end_paths if hex in path), [])\n",
    "        result.append(dead_end_path)\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "def divide_into_sections(arr):\n",
    "    \"\"\" Divides a sorted list of numbers into sections of consecutive numbers increasing by 1.\n",
    "    \n",
    "    Parameters: \n",
    "    arr (list): A sorted list of numbers with potential breaks. \n",
    "    \n",
    "    Returns: \n",
    "    result (list): A list where each section of increasing numbers is represented by consecutive integers.\n",
    "    \n",
    "    (I use this function to find each distinct time a rat enters a dead end path.)\n",
    "\n",
    "    Example:\n",
    "    >>> input_array = [7, 8, 9, 10, 11, 55, 56, 57, 58, 59, 60, 61, 990, 991, 992, 993]\n",
    "    >>> result_array = divide_into_sections(input_array)\n",
    "    >>> print(result_array)\n",
    "    [1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3]\n",
    "    \"\"\"\n",
    "\n",
    "    result = [0]*len(arr)\n",
    "    current_section = 1\n",
    "    \n",
    "    for i in range(1, len(arr)):\n",
    "        if arr[i] != arr[i-1] + 1:\n",
    "            current_section += 1\n",
    "        result[i] = current_section\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "def count_entries_for_each_dead_end(dead_end_paths, list_of_entries):\n",
    "    \"\"\" Count the number of times the rat entered a specific dead end\n",
    "\n",
    "    Args:\n",
    "    dead_end_paths (list): A list representing the areas a person entered\n",
    "    list_of_entries (list): A list representing distinct instances of area entry\n",
    "\n",
    "    Returns:\n",
    "    result: A list of counts, where each count represents how many times the rat entered a specific dead end\n",
    "    dead_end_counts: A dictionary representing the number of times the rat entered the path to each dead end\n",
    "    \"\"\"\n",
    "    \n",
    "    result = []\n",
    "    dead_end_counts = {}\n",
    "    distinct_entries = set()\n",
    "    \n",
    "    # replace each dead end path with just the dead end hex to make things easier\n",
    "    dead_ends = [sublist[0] for sublist in dead_end_paths]\n",
    "    \n",
    "    for de, entry in zip(dead_ends, list_of_entries):    \n",
    "        # if this is a new entry into a dead end, start or add to the entry count for this dead end\n",
    "        if entry not in distinct_entries:\n",
    "            if de not in dead_end_counts: \n",
    "                dead_end_counts[de] = 1\n",
    "            else:\n",
    "                dead_end_counts[de] += 1\n",
    "            # add this to our set of distinct entries so we don't double count it\n",
    "            distinct_entries.add(entry)\n",
    "            \n",
    "        result.append(dead_end_counts[de])\n",
    "        \n",
    "    return result, dead_end_counts\n",
    "\n",
    "\n",
    "def find_turnaround_index_hexes(rats_hex_path, dead_end_path):\n",
    "    \"\"\" Find the index where the rat turned around when going down a dead end path, using hexes.\n",
    "    \n",
    "    Parameters: \n",
    "    rats_hex_path: The path the rat took through the dead end (in hexes)\n",
    "    dead_end_path: The dead end path that the rat is in (hexes)\n",
    "    \n",
    "    Returns: \n",
    "    entered_index, exited_index: indices of the last time the rat entered and exited the furthest hex in the path\n",
    "    \"\"\"\n",
    "    \n",
    "    # find the furthest hex along the dead end path we get to before turning around\n",
    "    for hex in dead_end_path:\n",
    "        if hex in rats_hex_path.values:\n",
    "            furthest_hex = hex\n",
    "            break \n",
    "    \n",
    "    # we didn't get past the first hex, entered/exited indices are just the first and last indices\n",
    "    first_hex = rats_hex_path.values[0]\n",
    "    if first_hex == furthest_hex:\n",
    "        entered_index = 0\n",
    "        exited_index = len(rats_hex_path)-1\n",
    "        return entered_index, exited_index\n",
    "    \n",
    "    # otherwise, find the indices of the last time we entered and exited the furthest hex\n",
    "    turnaround_indices = []\n",
    "    for i in range(len(rats_hex_path) - 1):\n",
    "        if rats_hex_path.values[i] != furthest_hex and rats_hex_path.values[i+1] == furthest_hex:\n",
    "            entered_index = i+1\n",
    "        elif rats_hex_path.values[i] == furthest_hex and rats_hex_path.values[i+1] != furthest_hex:\n",
    "            exited_index = i\n",
    "    \n",
    "    return entered_index, exited_index\n",
    "\n",
    "\n",
    "def find_furthest_point_from_endpoints(x_coords, y_coords):\n",
    "    \"\"\" Finds the index of the (x,y) coordinate that is furthest from both the first and last coordinates.\n",
    "    \n",
    "    Parameters: \n",
    "    x_coords: List of x coordinates\n",
    "    y_coords: List of y coordinates\n",
    "\n",
    "    Returns:\n",
    "    furthest_index (int): The index of the furthest coordinate\n",
    "    furthest_coordinate (tuple): The (x,y) coordinate that is furthest from both endpoints\n",
    "    \"\"\"\n",
    "    \n",
    "    start_x, start_y = x_coords.iloc[0], y_coords.iloc[0]\n",
    "    end_x, end_y = x_coords.iloc[-1], y_coords.iloc[-1]\n",
    "\n",
    "    max_combined_distance = 0\n",
    "    furthest_coordinate = []\n",
    "    furthest_index = []\n",
    "\n",
    "    for i, (x, y) in enumerate(zip(x_coords, y_coords)):\n",
    "        distance_to_start = math.sqrt((x - start_x) ** 2 + (y - start_y) ** 2)\n",
    "        distance_to_end = math.sqrt((x - end_x) ** 2 + (y - end_y) ** 2)\n",
    "\n",
    "        combined_distance = distance_to_start + distance_to_end\n",
    "        if combined_distance > max_combined_distance:\n",
    "            max_combined_distance = combined_distance\n",
    "            furthest_coordinate = (x, y)\n",
    "            furthest_index = i\n",
    "\n",
    "    furthest_index = furthest_index + min(x_coords.index) # adjust for index in the dataframe\n",
    "\n",
    "    return furthest_index, furthest_coordinate\n",
    "\n",
    "\n",
    "def find_dead_end_turnaround(x_coords, y_coords, rats_hex_path, dead_end_path):\n",
    "    \"\"\" Finds the index where the rat turned around in a dead end path \"\"\"\n",
    "    \n",
    "    # find where the rat entered and exited the furthest hex in the dead end path\n",
    "    entered_index, exited_index = find_turnaround_index_hexes(rats_hex_path, dead_end_path)\n",
    "    \n",
    "    # find the furthest point in that hex from the entry and exit points\n",
    "    x = x_coords[entered_index:exited_index]\n",
    "    y = y_coords[entered_index:exited_index]\n",
    "    turnaround_index, turnaround_coordinate = find_furthest_point_from_endpoints(x, y)\n",
    "    \n",
    "    return turnaround_index\n",
    "\n",
    "\n",
    "def stats_for_dead_end_entry(rats_hex_path):\n",
    "    \"\"\" Given the rat's path in a dead end (in hexes), return hexes traveled and time spent in this dead end \"\"\"\n",
    "    \n",
    "    hexes_traveled = len(set(rats_hex_path))\n",
    "    time_spent = len(rats_hex_path)*1/250 # time (s) = number of samples * seconds per sample\n",
    "    \n",
    "    return hexes_traveled, time_spent\n",
    "\n",
    "\n",
    "def get_stats(df):\n",
    "    ''' fix me!! '''\n",
    "    num_dead_end_entries = max(df.individual_dead_end_entry)+1\n",
    "    hexes_traveled = [0]*(num_dead_end_entries)\n",
    "    time_spent = [0]*(num_dead_end_entries)\n",
    "    \n",
    "    for entry in list(range(1, num_dead_end_entries)):\n",
    "        hexes = df.hexlabels[df.individual_dead_end_entry==entry]\n",
    "    \n",
    "        # get stats for this entry\n",
    "        hexes_traveled[entry-1], time_spent[entry-1] = stats_for_dead_end_entry(hexes)\n",
    "    \n",
    "    return hexes_traveled, time_spent\n",
    "\n",
    "def get_centered_indices(df):\n",
    "    num_dead_end_entries = max(df.dead_end_entry)+1\n",
    "    centered_indices = [0] # should be empty, just an adjustment for this df\n",
    "    for entry in list(range(1, num_dead_end_entries)):\n",
    "        entry_df = dead_end_df[dead_end_df.dead_end_entry==entry]\n",
    "        dead_end_path = entry_df.dead_end_path.iloc[0]\n",
    "        turnaround_index = find_dead_end_turnaround(entry_df.x, entry_df.y, entry_df.hexlabels, dead_end_path)\n",
    "        indices = (entry_df.index - turnaround_index)\n",
    "        centered_indices += indices.tolist()\n",
    "    return centered_indices\n",
    "\n",
    "def get_mean_and_std(df, data_name, start_index, end_index):\n",
    "    ''' Messy function for now to take a dataframe, desired data (ex 'green_z_scored'), \n",
    "    and return the mean and standard deviation over all dead end entries, centered around\n",
    "    the dead end turnaround point. \n",
    "    '''\n",
    "    \n",
    "    filtered_df = df[(df['centered_indices'] >= start_index) & (df['centered_indices'] <= end_index)]\n",
    "    num_dead_end_entries = max(df.dead_end_entry)+1\n",
    "    \n",
    "    # Create a common index range from start to end\n",
    "    common_indices = np.arange(start_index, end_index + 1)\n",
    "    extended_lists = []\n",
    "\n",
    "    # Extend and interpolate values for each list to match the common index range\n",
    "    for entry in list(range(1, num_dead_end_entries)):\n",
    "        data = filtered_df[data_name][filtered_df.dead_end_entry==entry]\n",
    "        valid_indices = filtered_df.centered_indices[filtered_df.dead_end_entry==entry]\n",
    "    \n",
    "        # Create an array of NaN values with the length of the common index range\n",
    "        extended_values = np.full(end_index - start_index + 1, np.nan)\n",
    "\n",
    "        # Assign the valid values to the corresponding positions in the extended array\n",
    "        extended_values[valid_indices - start_index] = data\n",
    "        extended_lists.append(extended_values)\n",
    "    \n",
    "    mean_array = np.nanmean(extended_lists, axis=0)\n",
    "    std_array = np.nanstd(extended_lists, axis=0)\n",
    "    \n",
    "    return mean_array, std_array\n",
    "\n",
    "def plot_mean_and_std(mean_array, std_array, start_index, end_index, ylabel=None):\n",
    "    upper_bound = mean_array + std_array\n",
    "    lower_bound = mean_array - std_array\n",
    "    common_indices = np.arange(start_index, end_index + 1)\n",
    "    time = convert_indices_to_time(common_indices, -1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(time, mean_array, linewidth=2)\n",
    "    plt.fill_between(time, lower_bound, upper_bound, color='blue', alpha=0.2)\n",
    "    plt.xlabel('Time (s)')\n",
    "    if ylabel is not None:\n",
    "        plt.ylabel(ylabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf3a119",
   "metadata": {},
   "source": [
    "Do the dataframe loading and slicing in its own cell because it is slooow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4dee2921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 522.47 MB\n",
      "Memory usage after optimization is: 122.46 MB\n",
      "Decreased by 76.6%\n"
     ]
    }
   ],
   "source": [
    "specific_path = \"IM-1478/07202022\"\n",
    "#specific_path = \"IM-1478/07172022\"\n",
    "phot_path_base = \"/Volumes/Tim/Photometry/\"\n",
    "ephys_path_base = \"/Volumes/Tim/Ephys/\"\n",
    "min_dead_end_length = 3\n",
    "\n",
    "# Load transition matrix and dataframe for this session\n",
    "transition_mat = np.load(phot_path_base+specific_path+\"/tmat.npy\")\n",
    "df = reduce_mem_usage(pd.read_csv(ephys_path_base+specific_path+\"/phot_decode_df_withHexStates.csv\"))\n",
    "minx, miny, maxx, maxy = get_bounds(df)\n",
    "\n",
    "# Load pdf image of hexes from this session to use as the plot background\n",
    "image = convert_from_path(phot_path_base+specific_path+\"/hex_layout.pdf\")\n",
    "image[0].save('hex_background.png', 'png')\n",
    "\n",
    "# Use the transition matrix to get paths to dead end hexes\n",
    "dead_end_paths = get_all_dead_end_paths(transition_mat, min_dead_end_length)\n",
    "\n",
    "# Get subset of dataframe where rat the is in dead ends\n",
    "dead_end_hexes = [hex for path in dead_end_paths for hex in path]\n",
    "indices = [i for i in df.index if df['hexlabels'][i] in dead_end_hexes]\n",
    "dead_end_df = df.loc[df.index.isin(indices)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f733e756",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "- Add a bunch of columns to the dataframe to make it easy to slice and iterate based on different things\n",
    "- Print some stats about this session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5a9ebe2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths to dead end hexes: [[11, 8, 6], [18, 22, 27], [21, 17, 13]]\n",
      "The rat entered a dead end path 38 times in this session.\n",
      "Entry counts for each dead end path: {21: 7, 11: 14, 18: 17}\n"
     ]
    }
   ],
   "source": [
    "# Add column to the dataframe labeling which dead end path we are in\n",
    "print(\"Paths to dead end hexes:\", dead_end_paths)\n",
    "path = find_dead_end_path_for_hex(dead_end_df.hexlabels, dead_end_paths)\n",
    "dead_end_df['dead_end_path'] = path\n",
    "\n",
    "# Add column to the dataframe counting each entry into a dead end path (one count for all dead end paths)\n",
    "dead_end_entry = divide_into_sections(dead_end_df.index)\n",
    "dead_end_df['dead_end_entry'] = dead_end_entry\n",
    "print(\"The rat entered a dead end path\", max(dead_end_entry)+1, \"times in this session.\")\n",
    "\n",
    "# Add column to the dataframe counting the entry into each dead end path (different counts for each dead end path)\n",
    "individual_dead_end_entry, dead_end_counts = count_entries_for_each_dead_end(path, dead_end_entry)\n",
    "dead_end_df['individual_dead_end_entry'] = individual_dead_end_entry\n",
    "print(\"Entry counts for each dead end path:\", dead_end_counts)\n",
    "\n",
    "# Add columns to the dataframe indicating how far down a dead end path we got and how long we spent in that path\n",
    "hexes_traveled_list, time_spent_list = get_stats(dead_end_df)\n",
    "dead_end_df['max_hexes_traveled'] = expand_second_list(dead_end_entry, hexes_traveled_list)\n",
    "dead_end_df['time_in_dead_end'] = expand_second_list(dead_end_entry, time_spent_list)\n",
    "\n",
    "# Add column to the dataframe of indices centered around the turnaround point\n",
    "dead_end_df['centered_indices'] = get_centered_indices(dead_end_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "8bd344de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired start and end indices\n",
    "start_index = -500\n",
    "end_index = 500\n",
    "#data_name = 'vel'\n",
    "#data_name = 'green_z_scored'\n",
    "data_name = 'decodeDistToRat'\n",
    "\n",
    "# Plot mean and standard deviation of whatever data we're interested in\n",
    "mean_arr, std_arr = get_mean_and_std(dead_end_df, data_name, start_index, end_index)\n",
    "plot_mean_and_std(mean_arr, std_arr, start_index, end_index, data_name)\n",
    "\n",
    "# Plot all of the lines just to see if we have anything weird going on\n",
    "plot_all_lines_check = False\n",
    "if plot_all_lines_check:\n",
    "    fig, ax = plt.subplots()\n",
    "    filtered_df = dead_end_df[(dead_end_df['centered_indices'] >= start_index) & (dead_end_df['centered_indices'] <= end_index)]\n",
    "    num_dead_end_entries = max(dead_end_df.dead_end_entry)+1\n",
    "    for entry in list(range(1, num_dead_end_entries)):\n",
    "        data = filtered_df[data_name][filtered_df.dead_end_entry==entry]\n",
    "        idx = filtered_df.centered_indices[filtered_df.dead_end_entry==entry]\n",
    "        ax.plot(convert_indices_to_time(idx, -1), data)\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(data_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "e4c5ce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "hexes_traveled_list, time_spent_list = get_stats(dead_end_df)\n",
    "plot_histograms(hexes_traveled_list, time_spent_list)\n",
    "\n",
    "# ok, do the same thing for an individual dead end!\n",
    "for path in dead_end_paths:\n",
    "    slice_df = dead_end_df[dead_end_df['dead_end_path'].apply(lambda x: np.array_equal(x, path))]\n",
    "    hexes_traveled_list, time_spent_list = get_stats(slice_df)\n",
    "    plot_histograms(hexes_traveled_list, time_spent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d9c2d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms(hexes_traveled_list, time_spent_list):\n",
    "    # Histogram of time spent in dead end\n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "    axs[0,0].hist(time_spent_list, bins=20, edgecolor='black', alpha=0.7)\n",
    "    axs[0,0].set_xlabel('Time (seconds)')\n",
    "    axs[0,0].set_ylabel('Count')\n",
    "    axs[0,0].set_title('Distribution of time spent in a dead end')\n",
    "\n",
    "    # Histogram of hexes traveled down dead end\n",
    "    axs[1,0].hist(hexes_traveled_list, bins=3, edgecolor='black', alpha=0.7)\n",
    "    axs[1,0].set_xlabel('Hexes traveled')\n",
    "    axs[1,0].set_ylabel('Count')\n",
    "    axs[1,0].set_title('Distribution of hexes traveled down dead end')\n",
    "\n",
    "    # now show these over time\n",
    "    axs[0,1].plot(time_spent_list, marker='o', linestyle='-')\n",
    "    axs[0,1].set_xlabel('Dead end entry')\n",
    "    axs[0,1].set_ylabel('Time (s)')\n",
    "    axs[0,1].set_title('Time spent in dead end')\n",
    "\n",
    "    axs[1,1].plot(hexes_traveled_list, marker='o', linestyle='-')\n",
    "    axs[1,1].set_xlabel('Dead end entry')\n",
    "    axs[1,1].set_ylabel('Hexes')\n",
    "    axs[1,1].set_title('Hexes traveled down dead end')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "1f453e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'index', 'green_z_scored', 'port', 'rwd', 'x', 'y',\n",
      "       'nom_rwd_a', 'nom_rwd_b', 'beamA', 'beamB', 'beamC', 'tri', 'block',\n",
      "       'nom_rwd_c', 'hexlabels', 'lenAC', 'lenBC', 'lenAB', 'dtop', 'fiberloc',\n",
      "       'session_type', 'session', 'rat', 'date', 'lastleave', 'nom_rwd_chosen',\n",
      "       'vel', 'pairedHexStates', 'acc', 'decodeDistToRat', 'decodeHPD',\n",
      "       'x_pred', 'y_pred', 'mua', 'theta_env', 'theta_phase',\n",
      "       'theta_phase_bin', 'pred_hexlabels', 'pred_hexState', 'dead_end_path',\n",
      "       'dead_end_entry', 'individual_dead_end_entry', 'max_hexes_traveled',\n",
      "       'time_in_dead_end', 'centered_indices'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dead_end_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84e2161",
   "metadata": {},
   "source": [
    "### Plot a bunch of things for a single entry into a dead end path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "0209378e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hexes traveled: 3\n",
      "Time spent in this dead end: 5.86 seconds\n"
     ]
    }
   ],
   "source": [
    "#entries = list(range(1, 38))\n",
    "entries = [4]\n",
    "for entry in entries:\n",
    "\n",
    "    # Plot instance(s) of when a rat is in a dead end\n",
    "    scale = 60\n",
    "    xshift = 10\n",
    "    yshift = -30\n",
    "\n",
    "    plot_direction_changes = True # if we want to highlight direction changes on the plot\n",
    "\n",
    "    # get subsets of data (it's faster than constantly accessing the dataframe (?) )\n",
    "    x = dead_end_df.x[dead_end_df.dead_end_entry==entry]\n",
    "    y = dead_end_df.y[dead_end_df.dead_end_entry==entry]\n",
    "    x_pred = dead_end_df.x_pred[dead_end_df.dead_end_entry==entry]\n",
    "    y_pred = dead_end_df.y_pred[dead_end_df.dead_end_entry==entry]\n",
    "    dopamine = dead_end_df.green_z_scored[dead_end_df.dead_end_entry==entry]\n",
    "    decode_dist = dead_end_df.decodeDistToRat[dead_end_df.dead_end_entry==entry]\n",
    "    theta_phase = dead_end_df.theta_phase[dead_end_df.dead_end_entry==entry]\n",
    "    idx = dead_end_df.index[dead_end_df.dead_end_entry==entry]\n",
    "    #vel = moving_average(dead_end_df.vel[dead_end_df.dead_end_entry==entry], 63)\n",
    "    time = convert_indices_to_time(idx)\n",
    "    hexes = dead_end_df.hexlabels[dead_end_df.dead_end_entry==entry]\n",
    "    \n",
    "    # get stats for this entry\n",
    "    hexes_traveled, time_spent = stats_for_dead_end_entry(hexes)\n",
    "    print(\"Hexes traveled:\", hexes_traveled)\n",
    "    print(\"Time spent in this dead end:\", time_spent, \"seconds\")\n",
    "    \n",
    "\n",
    "    # plot a bunch of stuff for a dead end entry!\n",
    "    img = plt.imread(\"hex_background.png\")\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2)\n",
    "\n",
    "    ax1.set_title(\"Rat's actual position\")\n",
    "    ax1.imshow(img, extent=[minx+xshift-scale, maxx+xshift+scale, maxy+yshift+scale, miny+yshift-scale])\n",
    "    im = ax1.scatter(x, y, c=time, alpha=0.1, cmap='autumn')\n",
    "    divider = make_axes_locatable(ax1)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    cbar = fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "    cbar.solids.set(alpha=1)\n",
    "\n",
    "    ax3.set_title(\"Decoded position\")\n",
    "    ax3.imshow(img, extent=[minx+xshift-scale, maxx+xshift+scale, maxy+yshift+scale, miny+yshift-scale])\n",
    "    ax3.scatter(x_pred, y_pred, c=time, alpha=0.5, cmap='autumn')\n",
    "\n",
    "    ax2.set_title(\"Dopamine\")\n",
    "    t1 = ax2.scatter(time, scale_to_bounds(theta_phase,dopamine), c='grey', alpha=0.1)\n",
    "    t1.set_label('Theta phase')\n",
    "    ax2.scatter(time, dopamine)\n",
    "    #ax2.set_xlabel(\"Time (s)\")\n",
    "    ax2.legend()\n",
    "\n",
    "    ax4.set_title(\"Decode distance\")\n",
    "    t2 = ax4.scatter(time, scale_to_bounds(theta_phase,decode_dist), c='grey', alpha=0.1)\n",
    "    t2.set_label('Theta phase')\n",
    "    ax4.plot(time, decode_dist)   \n",
    "    ax4.set_xlabel(\"Time (s)\")\n",
    "    ax4.legend()\n",
    "    \n",
    "    #ax4.set_title(\"Velocity\")\n",
    "    #ax4.set_xlabel(\"Time (s)\")\n",
    "    #ax4.scatter(time, vel)     \n",
    "\n",
    "    if plot_direction_changes:\n",
    "        # find turnaround point\n",
    "        dead_end_path = dead_end_df.dead_end_path[dead_end_df.dead_end_entry==entry].iloc[0]\n",
    "        turnaround_index = find_dead_end_turnaround(x, y, hexes, dead_end_path)\n",
    "    \n",
    "        # adjust index for plotting because time and smoothed velocity start from 0\n",
    "        adjusted_index = turnaround_index - min(x.index) \n",
    "    \n",
    "        # highlight this point on the plots in blue\n",
    "        ax1.scatter(x[turnaround_index], y[turnaround_index], c='aqua')\n",
    "        ax3.scatter(x_pred[turnaround_index], y_pred[turnaround_index], c='aqua')\n",
    "        ax2.scatter(time[adjusted_index], dopamine[turnaround_index], c='aqua')\n",
    "        ax4.scatter(time[adjusted_index], decode_dist[turnaround_index], c='aqua')\n",
    "        #ax4.scatter(time[adjusted_index], vel[adjusted_index], c='aqua')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f1bf9e",
   "metadata": {},
   "source": [
    "# (De)function definitions \n",
    "(aka functions I wrote once but no longer use but don't wanna delete yet so they r defunct haha get it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c53795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_direction_vector(x1, y1, x2, y2):\n",
    "    \"\"\" Calculate the direction vector from (x1, y1) to (x2, y2) \"\"\"\n",
    "    \n",
    "    delta_x = x2 - x1\n",
    "    delta_y = y2 - y1\n",
    "    magnitude = math.sqrt(delta_x**2 + delta_y**2)\n",
    "    if magnitude == 0:\n",
    "        return (0, 0)  # Avoid division by zero\n",
    "    return (delta_x / magnitude, delta_y / magnitude)\n",
    "\n",
    "\n",
    "def find_direction_change_indices(x_coords, y_coords, angle_threshold=1.57): # 1.5708 = 90 degrees in radians\n",
    "    \"\"\" Given a list of x and y coordinates and an angle_threshold, find the indices where \n",
    "    the direction between sucessive coordinates changed more than angle_threshold radians \n",
    "    \"\"\"\n",
    "    \n",
    "    if len(x_coords) < 3 or len(y_coords) < 3 or len(x_coords) != len(y_coords):\n",
    "        return []  # Invalid data\n",
    "    \n",
    "    direction_change_indices = []\n",
    "    \n",
    "    for i in range(1, len(x_coords) - 1):\n",
    "        prev_direction = calculate_direction_vector(x_coords[i-1], y_coords[i-1], x_coords[i], y_coords[i])\n",
    "        next_direction = calculate_direction_vector(x_coords[i], y_coords[i], x_coords[i+1], y_coords[i+1])\n",
    "        \n",
    "        # Check if either of the directions is zero (no movement)\n",
    "        if prev_direction == (0, 0) or next_direction == (0, 0):\n",
    "            continue\n",
    "        \n",
    "        # Calculate the angle between direction vectors using the dot product\n",
    "        dot_product = prev_direction[0] * next_direction[0] + prev_direction[1] * next_direction[1]\n",
    "        angle = math.acos(max(-1, min(1, dot_product)))\n",
    "        \n",
    "        # Check if the angle is greater than the threshold\n",
    "        if angle > angle_threshold:\n",
    "            # uncomment the print statement below for useful debugging \n",
    "            #print(\"angle: \",angle,\" xy-1: \",x_coords[i-1],\",\",y_coords[i-1],\" xy: \",x_coords[i],\",\", y_coords[i], \" xy+1: \",x_coords[i+1],\",\",y_coords[i+1],\"prev dir\",prev_direction,\"next dir\",next_direction)\n",
    "            direction_change_indices.append(i)\n",
    "    \n",
    "    return direction_change_indices\n",
    "\n",
    "def find_turnaround_index_xy(x, y):\n",
    "    \"\"\" Find the index of the furthest coordinate from the first coordinate in a list of x, y coordinates \"\"\"\n",
    "    \n",
    "    max_distance = 0\n",
    "    turnaround_index = []\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        distance = math.sqrt((x[i] - x[0]) ** 2 + (y[i] - y[0]) ** 2)\n",
    "        if distance > max_distance:\n",
    "            max_distance = distance\n",
    "            turnaround_index = [i]\n",
    "\n",
    "    return turnaround_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3f87fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369        13.0\n",
      "370        13.0\n",
      "371        13.0\n",
      "372        13.0\n",
      "373        13.0\n",
      "           ... \n",
      "1712029    27.0\n",
      "1712030    27.0\n",
      "1712031    27.0\n",
      "1712032    27.0\n",
      "1712033    27.0\n",
      "Name: hexlabels, Length: 163367, dtype: float16\n",
      "1\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime spent in this dead end:\u001b[39m\u001b[38;5;124m\"\u001b[39m, time_spent, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 16\u001b[0m num \u001b[38;5;241m=\u001b[39m get_stats_columns(dead_end_df\u001b[38;5;241m.\u001b[39mhexlabels, dead_end_df\u001b[38;5;241m.\u001b[39mdead_end_entry)\n",
      "Cell \u001b[0;32mIn[23], line 8\u001b[0m, in \u001b[0;36mget_stats_columns\u001b[0;34m(rats_hex_path, dead_end_entry)\u001b[0m\n\u001b[1;32m      6\u001b[0m indices \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i, num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dead_end_entry) \u001b[38;5;28;01mif\u001b[39;00m num \u001b[38;5;241m==\u001b[39m entry]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(indices)\n\u001b[0;32m----> 8\u001b[0m hexes \u001b[38;5;241m=\u001b[39m rats_hex_path\u001b[38;5;241m.\u001b[39mloc[indices]\n\u001b[1;32m      9\u001b[0m hexes_traveled, time_spent \u001b[38;5;241m=\u001b[39m stats_for_dead_end_entry(hexes)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentry\u001b[39m\u001b[38;5;124m\"\u001b[39m, entry)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1100\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1102\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1332\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1330\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_iterable(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1272\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1272\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_listlike_indexer(key, axis)\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1274\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1462\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1459\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1460\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1462\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, axis_name)\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: '[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368] not in index'"
     ]
    }
   ],
   "source": [
    "def get_stats_columns(rats_hex_path, dead_end_entry):\n",
    "\n",
    "    print(rats_hex_path)\n",
    "    for entry in (1, len(dead_end_entry)):\n",
    "        print(entry)\n",
    "        indices = [i for i, num in enumerate(dead_end_entry) if num == entry]\n",
    "        print(indices)\n",
    "        hexes = rats_hex_path.loc[indices]\n",
    "        hexes_traveled, time_spent = stats_for_dead_end_entry(hexes)\n",
    "        print(\"entry\", entry)\n",
    "        print(\"Hexes traveled:\", hexes_traveled)\n",
    "        print(\"Time spent in this dead end:\", time_spent, \"seconds\")\n",
    "        \n",
    "    return 0\n",
    "    \n",
    "num = get_stats_columns(dead_end_df.hexlabels, dead_end_df.dead_end_entry)\n",
    "    \n",
    "  #  result = []\n",
    "  #  dead_end_counts = {}\n",
    "  #  distinct_entries = set()\n",
    "    \n",
    "    # replace each dead end path with just the dead end hex to make things easier\n",
    "  #  dead_ends = [sublist[0] for sublist in dead_end_paths]\n",
    "    \n",
    "  #  for de, entry in zip(dead_ends, list_of_entries):    \n",
    "        # if this is a new entry into a dead end, start or add to the entry count for this dead end\n",
    "  #      if entry not in distinct_entries:\n",
    "  #          if de not in dead_end_counts: \n",
    "  #              dead_end_counts[de] = 1\n",
    "  #          else:\n",
    "   #             dead_end_counts[de] += 1\n",
    "            # add this to our set of distinct entries so we don't double count it\n",
    "  #          distinct_entries.add(entry)\n",
    "            \n",
    "  #      result.append(dead_end_counts[de])\n",
    "        \n",
    "   # return result, dead_end_counts\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
